{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 0\n",
      "Processing image 1\n",
      "Processing image 2\n",
      "Processing image 3\n",
      "Processing image 4\n",
      "Processing image 5\n",
      "Processing image 6\n",
      "Processing image 7\n",
      "Processing image 8\n",
      "Processing image 9\n",
      "Processing image 10\n",
      "Processing image 11\n",
      "Processing image 12\n",
      "Processing image 13\n",
      "Processing image 14\n",
      "Processing image 15\n",
      "Processing image 16\n",
      "Processing image 17\n",
      "Processing image 18\n",
      "Processing image 19\n",
      "Processing image 20\n",
      "Processing image 21\n",
      "Processing image 22\n",
      "Processing image 23\n",
      "Processing image 24\n",
      "Processing image 25\n",
      "Processing image 26\n",
      "Processing image 27\n",
      "Processing image 28\n",
      "Processing image 29\n",
      "Processing image 30\n",
      "Processing image 31\n",
      "Processing image 32\n",
      "Processing image 33\n",
      "Processing image 34\n",
      "Done feature extracting\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "vgg16_feature_list = []\n",
    "\n",
    "filenames = glob(\"north_coast_tw_resize/*\")\n",
    "\n",
    "for i, fname in enumerate(filenames):\n",
    "    print(\"Processing image {}\".format(i))\n",
    "    img = image.load_img(fname, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "\n",
    "    vgg16_feature = model.predict(img_data)\n",
    "    vgg16_feature_np = np.array(vgg16_feature)\n",
    "    vgg16_feature_list.append(vgg16_feature_np.flatten())\n",
    "print(\"Done feature extracting\")\n",
    "vgg16_feature_list_np = np.array(vgg16_feature_list)\n",
    "kmodel = KMeans(n_clusters=2, random_state=0)\n",
    "kmodel.fit(vgg16_feature_list_np)\n",
    "predictions = kmodel.predict(vgg16_feature_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:photo]",
   "language": "python",
   "name": "conda-env-photo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
