{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import random, cv2, os, sys, shutil\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import keras\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class image_clustering:\n",
    "\n",
    "    def __init__(self, folder_path=\"data\", n_clusters=10, max_examples=None, use_imagenets=False, use_pca=False):\n",
    "        paths = os.listdir(folder_path)\n",
    "        if max_examples == None:\n",
    "            self.max_examples = len(paths)\n",
    "        else:\n",
    "            if max_examples > len(paths):\n",
    "                self.max_examples = len(paths)\n",
    "            else:\n",
    "                self.max_examples = max_examples\n",
    "        self.n_clusters = n_clusters\n",
    "        self.folder_path = folder_path\n",
    "        random.shuffle(paths)\n",
    "        self.image_paths = paths[:self.max_examples]\n",
    "        self.use_imagenets = use_imagenets\n",
    "        self.use_pca = use_pca\n",
    "        del paths \n",
    "        try:\n",
    "            shutil.rmtree(\"output\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        print(\"\\n output folders created.\")\n",
    "        os.makedirs(\"output\")\n",
    "        for i in range(self.n_clusters):\n",
    "            os.makedirs(\"output/cluster\" + str(i))\n",
    "        print(\"\\n Object of class \\\"image_clustering\\\" has been initialized.\")\n",
    "\n",
    "    def load_images(self):\n",
    "        self.images = []\n",
    "        for file in self.image_paths:\n",
    "            self.images.append(cv2.cvtColor(cv2.resize(cv2.imread(self.folder_path + \"/\" + file), (224,224)), cv2.COLOR_BGR2RGB))\n",
    "        self.images = np.float32(self.images).reshape(len(self.images), -1)\n",
    "        self.images /= 255\n",
    "        print(\"\\n \" + str(self.max_examples) + \" images from the \" + self.folder_path + \"/\" + \"folder have been loaded in a random order.\")\n",
    "        \n",
    "    def get_new_imagevectors(self):\n",
    "        if self.use_imagenets == False:\n",
    "            self.images_new = self.images\n",
    "        else:            \n",
    "            if use_imagenets.lower() == \"vgg16\":\n",
    "                model1 = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"vgg19\":\n",
    "                model1 = keras.applications.vgg19.VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"resnet50\":\n",
    "                model1 = keras.applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"xception\":\n",
    "                model1 = keras.applications.xception.Xception(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"inceptionv3\":\n",
    "                keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"inceptionresnetv2\":\n",
    "                model1 = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"densenet\":\n",
    "                model1 = keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "            elif use_imagenets.lower() == \"mobilenetv2\":\n",
    "                model1 = keras.applications.mobilenetv2.MobileNetV2(input_shape=(224,224,3), alpha=1.0, depth_multiplier=1, include_top=False, weights='imagenet', pooling=None)\n",
    "            else:\n",
    "                print(\"\\n\\n Please use one of the following keras applications only [ \\\"vgg16\\\", \\\"vgg19\\\", \\\"resnet50\\\", \\\"xception\\\", \\\"inceptionv3\\\", \\\"inceptionresnetv2\\\", \\\"densenet\\\", \\\"mobilenetv2\\\" ] or False\")\n",
    "                sys.exit()\n",
    "            print(\"Done making model...\")\n",
    "            feature_list = []\n",
    "            for i, file in enumerate(self.image_paths):\n",
    "                print(\"Processing image {}\".format(i))\n",
    "                img = image.load_img(self.folder_path + \"/\" + file, target_size=(224, 224))\n",
    "                img_data = image.img_to_array(img)\n",
    "                img_data = np.expand_dims(img_data, axis=0)\n",
    "                img_data = preprocess_input(img_data)\n",
    "\n",
    "                feature = model1.predict(img_data)\n",
    "                feature_np = np.array(feature)\n",
    "                feature_list.append(feature_np.flatten())\n",
    "            print(\"Done feature extracting\")\n",
    "            images_temp = np.array(feature_list)\n",
    "            if self.use_pca == False: \n",
    "                self.images_new = images_temp\n",
    "            else: \n",
    "                model2 = PCA(n_components=None, random_state=728)\n",
    "                pca = model2.fit_transform(images_temp)\n",
    "                self.images_new = pca\n",
    "\n",
    "    def clustering(self):\n",
    "        model = KMeans(n_clusters=self.n_clusters, n_jobs=-1, random_state=728)\n",
    "        model.fit(self.images_new)\n",
    "        predictions = model.predict(self.images_new)\n",
    "        #print(predictions)\n",
    "        for i in range(self.max_examples):\n",
    "            shutil.copy2(self.folder_path+\"/\"+self.image_paths[i], \"output/cluster\"+str(predictions[i]))\n",
    "        print(\"\\n Clustering complete! \\n\\n Clusters and the respective images are stored in the \\\"output\\\" folder.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \t\t START\n",
      "\n",
      "\n",
      "\n",
      " output folders created.\n",
      "\n",
      " Object of class \"image_clustering\" has been initialized.\n",
      "\n",
      " 242 images from the flickr/kenting/preprocess//folder have been loaded in a random order.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nghianc/anaconda3/envs/photo/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done making model...\n",
      "Processing image 0\n",
      "Processing image 1\n",
      "Processing image 2\n",
      "Processing image 3\n",
      "Processing image 4\n",
      "Processing image 5\n",
      "Processing image 6\n",
      "Processing image 7\n",
      "Processing image 8\n",
      "Processing image 9\n",
      "Processing image 10\n",
      "Processing image 11\n",
      "Processing image 12\n",
      "Processing image 13\n",
      "Processing image 14\n",
      "Processing image 15\n",
      "Processing image 16\n",
      "Processing image 17\n",
      "Processing image 18\n",
      "Processing image 19\n",
      "Processing image 20\n",
      "Processing image 21\n",
      "Processing image 22\n",
      "Processing image 23\n",
      "Processing image 24\n",
      "Processing image 25\n",
      "Processing image 26\n",
      "Processing image 27\n",
      "Processing image 28\n",
      "Processing image 29\n",
      "Processing image 30\n",
      "Processing image 31\n",
      "Processing image 32\n",
      "Processing image 33\n",
      "Processing image 34\n",
      "Processing image 35\n",
      "Processing image 36\n",
      "Processing image 37\n",
      "Processing image 38\n",
      "Processing image 39\n",
      "Processing image 40\n",
      "Processing image 41\n",
      "Processing image 42\n",
      "Processing image 43\n",
      "Processing image 44\n",
      "Processing image 45\n",
      "Processing image 46\n",
      "Processing image 47\n",
      "Processing image 48\n",
      "Processing image 49\n",
      "Processing image 50\n",
      "Processing image 51\n",
      "Processing image 52\n",
      "Processing image 53\n",
      "Processing image 54\n",
      "Processing image 55\n",
      "Processing image 56\n",
      "Processing image 57\n",
      "Processing image 58\n",
      "Processing image 59\n",
      "Processing image 60\n",
      "Processing image 61\n",
      "Processing image 62\n",
      "Processing image 63\n",
      "Processing image 64\n",
      "Processing image 65\n",
      "Processing image 66\n",
      "Processing image 67\n",
      "Processing image 68\n",
      "Processing image 69\n",
      "Processing image 70\n",
      "Processing image 71\n",
      "Processing image 72\n",
      "Processing image 73\n",
      "Processing image 74\n",
      "Processing image 75\n",
      "Processing image 76\n",
      "Processing image 77\n",
      "Processing image 78\n",
      "Processing image 79\n",
      "Processing image 80\n",
      "Processing image 81\n",
      "Processing image 82\n",
      "Processing image 83\n",
      "Processing image 84\n",
      "Processing image 85\n",
      "Processing image 86\n",
      "Processing image 87\n",
      "Processing image 88\n",
      "Processing image 89\n",
      "Processing image 90\n",
      "Processing image 91\n",
      "Processing image 92\n",
      "Processing image 93\n",
      "Processing image 94\n",
      "Processing image 95\n",
      "Processing image 96\n",
      "Processing image 97\n",
      "Processing image 98\n",
      "Processing image 99\n",
      "Processing image 100\n",
      "Processing image 101\n",
      "Processing image 102\n",
      "Processing image 103\n",
      "Processing image 104\n",
      "Processing image 105\n",
      "Processing image 106\n",
      "Processing image 107\n",
      "Processing image 108\n",
      "Processing image 109\n",
      "Processing image 110\n",
      "Processing image 111\n",
      "Processing image 112\n",
      "Processing image 113\n",
      "Processing image 114\n",
      "Processing image 115\n",
      "Processing image 116\n",
      "Processing image 117\n",
      "Processing image 118\n",
      "Processing image 119\n",
      "Processing image 120\n",
      "Processing image 121\n",
      "Processing image 122\n",
      "Processing image 123\n",
      "Processing image 124\n",
      "Processing image 125\n",
      "Processing image 126\n",
      "Processing image 127\n",
      "Processing image 128\n",
      "Processing image 129\n",
      "Processing image 130\n",
      "Processing image 131\n",
      "Processing image 132\n",
      "Processing image 133\n",
      "Processing image 134\n",
      "Processing image 135\n",
      "Processing image 136\n",
      "Processing image 137\n",
      "Processing image 138\n",
      "Processing image 139\n",
      "Processing image 140\n",
      "Processing image 141\n",
      "Processing image 142\n",
      "Processing image 143\n",
      "Processing image 144\n",
      "Processing image 145\n",
      "Processing image 146\n",
      "Processing image 147\n",
      "Processing image 148\n",
      "Processing image 149\n",
      "Processing image 150\n",
      "Processing image 151\n",
      "Processing image 152\n",
      "Processing image 153\n",
      "Processing image 154\n",
      "Processing image 155\n",
      "Processing image 156\n",
      "Processing image 157\n",
      "Processing image 158\n",
      "Processing image 159\n",
      "Processing image 160\n",
      "Processing image 161\n",
      "Processing image 162\n",
      "Processing image 163\n",
      "Processing image 164\n",
      "Processing image 165\n",
      "Processing image 166\n",
      "Processing image 167\n",
      "Processing image 168\n",
      "Processing image 169\n",
      "Processing image 170\n",
      "Processing image 171\n",
      "Processing image 172\n",
      "Processing image 173\n",
      "Processing image 174\n",
      "Processing image 175\n",
      "Processing image 176\n",
      "Processing image 177\n",
      "Processing image 178\n",
      "Processing image 179\n",
      "Processing image 180\n",
      "Processing image 181\n",
      "Processing image 182\n",
      "Processing image 183\n",
      "Processing image 184\n",
      "Processing image 185\n",
      "Processing image 186\n",
      "Processing image 187\n",
      "Processing image 188\n",
      "Processing image 189\n",
      "Processing image 190\n",
      "Processing image 191\n",
      "Processing image 192\n",
      "Processing image 193\n",
      "Processing image 194\n",
      "Processing image 195\n",
      "Processing image 196\n",
      "Processing image 197\n",
      "Processing image 198\n",
      "Processing image 199\n",
      "Processing image 200\n",
      "Processing image 201\n",
      "Processing image 202\n",
      "Processing image 203\n",
      "Processing image 204\n",
      "Processing image 205\n",
      "Processing image 206\n",
      "Processing image 207\n",
      "Processing image 208\n",
      "Processing image 209\n",
      "Processing image 210\n",
      "Processing image 211\n",
      "Processing image 212\n",
      "Processing image 213\n",
      "Processing image 214\n",
      "Processing image 215\n",
      "Processing image 216\n",
      "Processing image 217\n",
      "Processing image 218\n",
      "Processing image 219\n",
      "Processing image 220\n",
      "Processing image 221\n",
      "Processing image 222\n",
      "Processing image 223\n",
      "Processing image 224\n",
      "Processing image 225\n",
      "Processing image 226\n",
      "Processing image 227\n",
      "Processing image 228\n",
      "Processing image 229\n",
      "Processing image 230\n",
      "Processing image 231\n",
      "Processing image 232\n",
      "Processing image 233\n",
      "Processing image 234\n",
      "Processing image 235\n",
      "Processing image 236\n",
      "Processing image 237\n",
      "Processing image 238\n",
      "Processing image 239\n",
      "Processing image 240\n",
      "Processing image 241\n",
      "Done feature extracting\n",
      "\n",
      " Clustering complete! \n",
      "\n",
      " Clusters and the respective images are stored in the \"output\" folder.\n",
      "\n",
      "\n",
      "\t\t END\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    !rm -rf output\n",
    "    !mkdir -p output\n",
    "\n",
    "    print(\"\\n\\n \\t\\t START\\n\\n\")\n",
    "\n",
    "    number_of_clusters = 10 # cluster names will be 0 to number_of_clusters-1\n",
    "\n",
    "    data_path = \"flickr/kenting/preprocess/\" # path of the folder that contains the images to be considered for the clustering (The folder must contain only image files)\n",
    "\n",
    "    max_examples = None # number of examples to use, if \"None\" all of the images will be taken into consideration for the clustering\n",
    "    # If the value is greater than the number of images present  in the \"data_path\" folder, it will use all the images and change the value of this variable to the number of images available in the \"data_path\" folder. \n",
    "\n",
    "    use_imagenets = \"ResNet50\"\n",
    "    # choose from: \"Xception\", \"VGG16\", \"VGG19\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"DenseNet\", \"MobileNetV2\" and \"False\" -> Default is: False\n",
    "\n",
    "    if use_imagenets == False:\n",
    "        use_pca = False\n",
    "    else:\n",
    "        use_pca = True # Make it True if you want to use PCA for dimentionaity reduction -> Default is: False\n",
    "\n",
    "    temp = image_clustering(data_path, number_of_clusters, max_examples, use_imagenets, use_pca)\n",
    "    temp.load_images()\n",
    "    temp.get_new_imagevectors()\n",
    "    temp.clustering()\n",
    "\n",
    "    print(\"\\n\\n\\t\\t END\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(0, number_of_clusters):\n",
    "#     print(\"Cluster {}\".format(i))\n",
    "#     file = glob(\"output/cluster{}/*\".format(i)) \n",
    "#     for f in file:\n",
    "#         image = Image.open(f)\n",
    "#         display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:photo]",
   "language": "python",
   "name": "conda-env-photo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
